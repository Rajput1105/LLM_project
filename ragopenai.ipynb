{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c5d58",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "import utils\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf27687",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# Load PDF documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"./IPCC_AR6_WGII_Chapter03.pdf\", \"./eBook-How-to-Build-a-Career-in-AI.pdf\"]).load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdbe1c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e8d17d",
   "metadata": {
    "height": 30
   },
   "source": [
    "### Basic rag pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b93c9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from llama_index import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5170ffa",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dir(Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9749f8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "doc=Document(text=\"/n/n\".join([docs.text for docs in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242cfc0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pip freeze | grep \"llama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893c055",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031218a8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dir(llama_index.vector_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90cb2bc",
   "metadata": {
    "height": 336
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.vector_stores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvector_stores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChromaVectorStore\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocstore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleDocumentStore\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindex_store\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleIndexStore\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.vector_stores'"
     ]
    }
   ],
   "source": [
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.storage.index_store import SimpleIndexStore\n",
    "from llama_index import StorageContext\n",
    "import chromadb\n",
    "\n",
    "# Setup ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"data\")\n",
    "\n",
    "# Configure storage context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store,\n",
    "    docstore=SimpleDocumentStore(),\n",
    "    index_store=SimpleIndexStore()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e8c13",
   "metadata": {
    "height": 30
   },
   "source": [
    "### Storing and indexing the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebb8e5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b20267",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "\n",
    "\n",
    "docs = SimpleDirectoryReader(input_files=[\"./IPCC_AR6_WGII_Chapter03.pdf\"]).load_data()\n",
    "\n",
    "\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "# index = VectorStoreIndex.from_documents([doc],\n",
    "#                                         service_context=service_context)\n",
    "# âœ… Step 2: Create an index using ChromaDB as a vector store\n",
    "# index = VectorStoreIndex.from_documents(docs, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484ba18",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    [doc], storage_context=storage_context, service_context=service_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34789df6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(index.index_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91353c37",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"./chroma_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8578d8",
   "metadata": {
    "height": 438
   },
   "outputs": [],
   "source": [
    "from llama_index import StorageContext, load_index_from_storage\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "import chromadb\n",
    "\n",
    "# # Load ChromaDB\n",
    "# chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "# chroma_collection = chroma_client.get_or_create_collection(\"data\")\n",
    "\n",
    "# # Load the persisted storage context with the vector store\n",
    "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store, persist_dir=\"./chroma_db\")\n",
    "\n",
    "# id='e87dbac9-0318-449c-82ad-2e09c65c4ebd'\n",
    "# # Load index from storage\n",
    "# index = load_index_from_storage(storage_context,index_id=[id])\n",
    "\n",
    "# # Create Query Engine\n",
    "# query_engine = index.as_query_engine()\n",
    "\n",
    "# # Run query\n",
    "# query = \"What are the key findings from Chapter 3 of the IPCC report?\"\n",
    "# response = query_engine.query(query)\n",
    "\n",
    "# print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ee41e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dir(llama_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae36dd4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from llama_index import load_indices_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f2901",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store, persist_dir=\"./chroma_db\")\n",
    "\n",
    "# Use the exact index_id from your persisted index\n",
    "index_id = \"e87dbac9-0318-449c-82ad-2e09c65c4ebd\"\n",
    "indices = load_indices_from_storage(storage_context, index_ids=[index_id])\n",
    "\n",
    "# Extract the index\n",
    "index = indices[0]\n",
    "\n",
    "# Create Query Engine\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Run query\n",
    "query = \"What are the key findings from Chapter 3 of the IPCC report?\"\n",
    "response = query_engine.query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aeb59a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "?load_indices_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ceca4e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57e1d3",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are steps to take when finding projects to build your experience?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe5d5d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ded105",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a3f08",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010aa36b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc964407",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
